## This week's progress

### TODO
- [ ] soleve NaN problem

### solve NaN problem
Tried changing the number of hidden layers and the activation function (ActName) to see if that prevents the NaN values.

```haskell

 MLPHypParams device 400 [(1000,Relu),(200,Relu), (1,Id)]

Loading embeddings...
Loading training data...
Initializing model...
Training...
inputs shape in trainMLP: [6523,400]
targets shape in trainMLP: [6523,1]
Iter 1: Loss = 60.135674
Iter 2: Loss = NaN
```

```haskell
MLPHypParams device 400 [(1000,Selu),(200,Selu), (1,Id)]

Loading embeddings...
Loading training data...
Initializing model...
Training...
inputs shape in trainMLP: [6523,400]
targets shape in trainMLP: [6523,1]
Iter 1: Loss = 40.274372
Iter 2: Loss = NaN
```

```haskell
MLPHypParams device 400 [(1000,Elu),(200,Elu), (1,Id)]

Loading embeddings...
Loading training data...
Initializing model...
Training...
inputs shape in trainMLP: [6523,400]
targets shape in trainMLP: [6523,1]
Iter 1: Loss = 51.302326
Iter 2: Loss = NaN
```
I tried changing the number of hidden layers to 256, 64 (with an input of 400 and an output of 1), and also tried changing the activation function (ActName). However, all attempts still resulted in NaN values at iter2.


**Added implementation to output the vector assigned to each word:** 
```haskell
Total words in embedding: 12
First 10 words in embedding:
勧誘
善
変わる
恭敬
教諭
気象学
水路
温かさ
育ち上る
行なわれる
Loading training data...
===== Sample Word Embeddings (first 10) =====
Hyper: 食付く, Embedding (first 5): [-0.991739,0.433873,-1.634327,-2.637119,1.87341]
Hypo : 水路, Embedding (first 5): [-0.591747,0.450768,-0.569417,-1.819948,1.233053]
Label: [0.0]
-------------------------------------------
Hyper: 気象学, Embedding (first 5): [1.452248,4.2669e-2,-1.314564,1.0381e-2,2.714643]
Hypo : 育ち上る, Embedding (first 5): [1.570539,0.394597,-2.445322,-2.895358,1.70258]
Label: [0.0]
-------------------------------------------
Hyper: 防止, Embedding (first 5): [0.860323,0.364299,-1.338088,-2.240771,1.269506]
Hypo : 善, Embedding (first 5): [-0.550911,1.442538,-1.497971,-3.820506,-0.579182]
Label: [1.0]
-------------------------------------------
Hyper: 教諭, Embedding (first 5): [-2.908279,0.234655,-0.807588,-4.26368,2.062142]
Hypo : 変わる, Embedding (first 5): [0.456306,0.220344,-2.7309,-2.613384,1.505659]
Label: [0.0]
-------------------------------------------
Hyper: 温かさ, Embedding (first 5): [0.557453,-1.057253,-0.392746,0.620759,0.986158]
Hypo : 恭敬, Embedding (first 5): [-3.341663,1.490729,1.415666,-5.043354,2.632028]
Label: [1.0]
-------------------------------------------
Hyper: 行なわれる, Embedding (first 5): [2.602264,-2.635719,-2.582198,-2.742836,-1.908443]
Hypo : 持ち上る, Embedding (first 5): [0.0,0.0,0.0,0.0,0.0] [ZERO VECTOR!]
Label: [1.0]
-------------------------------------------
Hyper: 勧誘, Embedding (first 5): [2.167533,1.266657,-0.277014,0.605125,4.747177]
Hypo : 烙印, Embedding (first 5): [0.0,0.0,0.0,0.0,0.0] [ZERO VECTOR!]
Label: [0.0]
-------------------------------------------
Hyper: 捨去る, Embedding (first 5): [0.0,0.0,0.0,0.0,0.0] [ZERO VECTOR!]
Hypo : 現像, Embedding (first 5): [0.0,0.0,0.0,0.0,0.0] [ZERO VECTOR!]
Label: [0.0]
-------------------------------------------
Hyper: 事業年度, Embedding (first 5): [0.0,0.0,0.0,0.0,0.0] [ZERO VECTOR!]
Hypo : 嫌疑者, Embedding (first 5): [0.0,0.0,0.0,0.0,0.0] [ZERO VECTOR!]
Label: [0.0]
-------------------------------------------
```

It seems that words existing within the embedding are properly assigned vectors. Even after removing pairs that result in a 0-vector and re-running, the issue of getting NaN values from iter2 onwards was not resolved. This problem seems like it will take some time to fix, so for now, I'll proceed with implementing Hyperbolic Embedding.


**Tried with randomly initialized embeddings**
```haskell:MLPRandomMain.hs
Initializing random embeddings...
Total words in embedding: 18
First 10 words in embedding:
事業年度
勧誘
善
変わる
嫌疑者
恭敬
持ち上る
捨去る
教諭
気象学
Loading training data...
===== Sample Word Embeddings (first 10) =====
Hyper: 食付く, Embedding (first 5): [-9.36578e-2,7.437455e-2,-7.2709255e-2,-8.861575e-2,2.7236525e-2]
Hypo : 水路, Embedding (first 5): [-3.4551132e-2,-9.7310655e-2,6.886337e-2,7.852292e-2,1.8762499e-3]
Label: [0.0]
-------------------------------------------
Hyper: 気象学, Embedding (first 5): [-3.3884052e-2,-7.620872e-2,9.243336e-2,1.3461728e-2,5.0986238e-2]
Hypo : 育ち上る, Embedding (first 5): [9.506168e-2,2.2093698e-2,-9.606717e-2,-1.1676952e-2,-4.660619e-2]
Label: [0.0]
-------------------------------------------
Hyper: 防止, Embedding (first 5): [9.709152e-2,-9.499652e-2,-7.485572e-2,-3.2867495e-2,7.975992e-2]
Hypo : 善, Embedding (first 5): [5.477888e-2,-9.196078e-2,-3.9486818e-2,-3.614216e-2,-1.6989969e-2]
Label: [1.0]
-------------------------------------------
Hyper: 教諭, Embedding (first 5): [1.625545e-2,2.6930306e-2,2.6802134e-2,9.4256096e-2,2.6532713e-2]
Hypo : 変わる, Embedding (first 5): [-9.301712e-2,4.9605705e-2,6.0746796e-2,-7.8726195e-2,-7.633602e-2]
Label: [0.0]
-------------------------------------------
Hyper: 温かさ, Embedding (first 5): [3.5045743e-2,7.845551e-2,-4.9429737e-2,-6.459415e-2,-3.781772e-2]
Hypo : 恭敬, Embedding (first 5): [6.55609e-2,1.7361082e-2,-7.111064e-2,8.7054275e-2,6.402614e-2]
Label: [1.0]
-------------------------------------------
Hyper: 行なわれる, Embedding (first 5): [3.1488013e-2,4.262142e-2,-2.4556622e-2,-6.366163e-2,6.753459e-2]
Hypo : 持ち上る, Embedding (first 5): [6.3144214e-2,-1.7957292e-2,7.4374534e-2,-5.001322e-2,-2.308847e-2]
Label: [1.0]
-------------------------------------------
Hyper: 勧誘, Embedding (first 5): [1.4518265e-2,1.4044531e-3,-2.9761046e-3,-9.585873e-2,-1.6352057e-2]
Hypo : 烙印, Embedding (first 5): [-8.838322e-2,9.689341e-2,-3.0509043e-2,-4.267662e-2,-8.580493e-2]
Label: [0.0]
-------------------------------------------
Hyper: 捨去る, Embedding (first 5): [7.0805997e-3,-2.068653e-2,7.704999e-2,6.2249564e-2,9.8017745e-2]
Hypo : 現像, Embedding (first 5): [-1.985009e-2,-3.7602477e-2,-8.135427e-2,3.3639293e-2,4.4063e-2]
Label: [0.0]
-------------------------------------------
Hyper: 事業年度, Embedding (first 5): [7.977958e-2,8.352288e-2,2.7091317e-3,-4.5807187e-2,-5.7654954e-2]
Hypo : 嫌疑者, Embedding (first 5): [6.866468e-2,4.1317407e-2,-6.35457e-2,-8.122326e-2,-4.9225837e-3]
Label: [0.0]
-------------------------------------------
Input data stats:
  Min value: -9.993925e-2
  Max value: 9.9986576e-2
  Mean value: -5.0889567e-4
Initializing model...
Training...
inputs shape in trainMLP: [9,400]
targets shape in trainMLP: [9,1]
yPred: Tensor Float [9] [ 0.3341   ,  0.3335   ,  0.3349   ,  0.3343   ,  0.3343   ,  0.3338   ,  0.3343   ,  0.3339   ,  0.3341   ]
Iter 1: Loss = 44.45716
yPred: Tensor Float [9] [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN]
Iter 2: Loss = NaN
yPred: Tensor Float [9] [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN]
Iter 3: Loss = NaN
yPred: Tensor Float [9] [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN]
Iter 4: Loss = NaN
yPred: Tensor Float [9] [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN]
Iter 5: Loss = NaN
yPred: Tensor Float [9] [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN]
Iter 6: Loss = NaN
yPred: Tensor Float [9] [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN]
```
failed :(